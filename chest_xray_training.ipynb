{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying Disease with Deep Learning\n",
    "\n",
    "Neural networks have shown incredible capabilities in image classification, which is the task of labeling an image based on its content. While most of the intial work on this space was for identifying common items and objects - like cars, plants, refrigerators, dogs, and cats - this proof of concept capability is only a stepping stone to being able to classify images which can have a dramatic impact on society.\n",
    "\n",
    "One industry that will be transformed through the use of neural networks is medicine. The ability for computers to classify disease based on xray/CT/MRI images will make medicine more efficient, more economical, and more accurate.\n",
    "\n",
    "## Building a Neural Network to Identify Disease in Chest Xrays\n",
    "\n",
    "We'll be using a common neural network topology (ResNet50) to identify pneumonia, emphysema, and other thoracic conditions in chest xray images. For this exercise, we will be using the Keras framework, which is an abstraction on top of TensorFlow which provides a simpler method for describing neural networks.\n",
    "\n",
    "## Preamble\n",
    "\n",
    "The first thing we'll do is import the Python packages we will need to build and train our neural network: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "import tensorflow.keras as keras\n",
    "import time\n",
    "import PIL.Image as pil\n",
    "import PIL.ImageOps\n",
    "\n",
    "tensorflow.logging.set_verbosity(tensorflow.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Hyperparameter and Global Variables\n",
    "\n",
    "Setting all of the hyperparameters and global variables at the beginning will make it easier for us to change the experiment later. Typically a data scientist will spend a fair amount of time tuning variables and retraining the network in order to achieve the highest possible accuracy from the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_OUTPUT_PATH = os.environ.get('HOME') + \"/notebooks/output/experiment\"\n",
    "IMAGES_PATH = os.environ.get('HOME') + \"/notebooks/images_all\"\n",
    "TRAINING_LABELS = os.environ.get('HOME') + \"/notebooks/training_labels_new.pkl\"\n",
    "VALIDATION_LABELS = os.environ.get('HOME') + \"/notebooks/validation_labels_new.pkl\"\n",
    "\n",
    "IMAGE_SIZE = 256\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 1\n",
    "LEARNING_RATE = 0.001\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "In order to train the neural network on chest xray images, we need some helper functions that:\n",
    "* attach labels to training and validation images\n",
    "* resize images to fit in the neural network\n",
    "* load batches of training images for training the network\n",
    "* load batches of validation images for determining the network's accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAINING_LABELS, 'rb') as f:\n",
    "  training_labels = pickle.load(f)\n",
    "training_files = np.asarray(list(training_labels.keys()))\n",
    "\n",
    "with open(VALIDATION_LABELS, 'rb') as f:\n",
    "  validation_labels = pickle.load(f)\n",
    "validation_files = np.asarray(list(validation_labels.keys()))\n",
    "labels = dict(list(training_labels.items()) + list(validation_labels.items()))\n",
    "\n",
    "def load_batch(batch_of_files,is_training=False):\n",
    "  batch_images = []\n",
    "  batch_labels = []\n",
    "  for filename in batch_of_files:\n",
    "    img = pil.open(os.path.join(IMAGES_PATH, filename))\n",
    "    img = img.convert('RGB')\n",
    "    img = img.resize((IMAGE_SIZE, IMAGE_SIZE),pil.NEAREST)\n",
    "    if is_training and np.random.randint(2):\n",
    "      img = PIL.ImageOps.mirror(img)\n",
    "    batch_images.append(np.asarray(img))\n",
    "    batch_labels.append(labels[filename])\n",
    "  return keras.applications.resnet50.preprocess_input(np.float32(np.asarray(batch_images))), np.asarray(batch_labels)\n",
    "\n",
    "def train_generator(num_of_steps):\n",
    "  while True:\n",
    "    np.random.shuffle(training_files)\n",
    "    for i in range(num_of_steps):\n",
    "      batch_of_files = training_files[i*BATCH_SIZE: i*BATCH_SIZE + BATCH_SIZE]\n",
    "      batch_images, batch_labels = load_batch(batch_of_files, True)\n",
    "      yield batch_images, batch_labels\n",
    "\n",
    "def val_generator(num_of_steps):\n",
    "  while True:\n",
    "    np.random.shuffle(validation_files)\n",
    "    for i in range(num_of_steps):\n",
    "      batch_of_files = validation_files[i*BATCH_SIZE: i*BATCH_SIZE + BATCH_SIZE]\n",
    "      batch_images, batch_labels = load_batch(batch_of_files, True)\n",
    "      yield batch_images, batch_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Neural Network\n",
    "\n",
    "Now we can build the neural network. We will start by using a ResNet-50 topology pretrained on the ImageNet dataset. We use a pretrained model in order to reduce the time to train. This concept - called _transfer learning_ - is broadly applicable to many use cases, especially in image classification.\n",
    "\n",
    "Keras allows us to generate a standard topology (in this case ResNet-50), populate it with pretrained weights, and remove the classification layer so that we can attach a new classifier for our own needs.\n",
    "\n",
    "In this case we don't need a classifier for 1000 different common objects. We need a classifier for 14 different thoracic pathologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dlab/shared/python/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "base_model = keras.applications.ResNet50(include_top=False, weights='imagenet', input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "feature_extractors = keras.layers.GlobalAvgPool2D(data_format='channels_last')(base_model.output)\n",
    "predictions = keras.layers.Dense(14, activation='sigmoid', bias_initializer='ones')(feature_extractors)\n",
    "\n",
    "model = keras.Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the Neural Network\n",
    "\n",
    "Next, we will compile the neural network description and associate a loss function, an optimizer function, and the metrics which will be used for optimization. In this case, we use:\n",
    "* Binary Crossentropy loss\n",
    "* Adam optimizer - this optimizer works well for quickly optimizing networks (however, this optimizer does not work well for parallelized training)\n",
    "* Optimize on network accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=keras.optimizers.Adam(lr=LEARNING_RATE),\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Disease Identification Model\n",
    "\n",
    "Now we can 'fit' the compiled neural network to the training data. This will produce a _model_ (or a trained neural network) which can accurately identify diseases such as pneumonia and emphysema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_file= EXPERIMENT_OUTPUT_PATH + '/lr_{:.3f}_bz_{:d}'.format(0.001, 16) + '_loss_{val_loss:.3f}_epoch_{epoch:02d}.h5'\n",
    "\n",
    "#steps_per_epoch = 77871 // BATCH_SIZE\n",
    "#val_steps = 8653 // BATCH_SIZE\n",
    "\n",
    "steps_per_epoch = 77871 // BATCH_SIZE\n",
    "val_steps = 8653 // BATCH_SIZE\n",
    "\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator(steps_per_epoch),\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    validation_data=val_generator(val_steps),\n",
    "    validation_steps=val_steps,\n",
    "    callbacks=[ ],\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model can take a *LONG* time\n",
    "\n",
    "Deep neural networks take a long time to train. In many cases, especially when the problem space is new and not well understood, they might need days or weeks to produce accurate models. If you have to do hyperparameter tuning, means you have to iteratively repeat this process many times over.\n",
    "\n",
    "This means that producing a production model could take months!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
